---
description: Streaming AI Applications
---

# LangStream Documentation

The LangStream project combines the intelligence of large language models with the agility of streaming processing, to create powerful processing applications.

An application in LangStream can watch a message topic and process data through multiple steps to output some useful generative AI results. Say you have a goal of creating a chatbot that can stay up-to-date with some dataset that is constantly changing. As someone interacts with the bot, they are offered educated meaningful answers that help them navigate some workflow.

### Features

* Run in any Kubernetes cluster using our helm chart
* Connect to popular event streaming platforms like [Apache Kafka](https://kafka.apache.org/) and [Apache Pulsar](https://pulsar.apache.org/)
* Leverage LLMs like [ChatGPT](https://openai.com/), inference APIs like [HuggingFace](https://huggingface.co/), vector databases like [AstraDB](https://www.datastax.com/products/datastax-astra), and chaining agents like [LangChain](https://js.langchain.com/docs/get\_started/introduction) with our included agents, no code required
* Create your own real-time AI application pipelines with simple, declarative YAML files

Get started [here!](get-started.md)
